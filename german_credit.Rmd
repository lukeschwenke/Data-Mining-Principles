---
title: "Assignment #1: German Credit"
author: "Luke Schwenke"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(caret)
library(dplyr)
library(ggplot2)

data(GermanCredit)
```

# Regression Model

```{r model, echo=TRUE, warning=FALSE}

df <- GermanCredit
df <- df %>% dplyr::select(-Class) # Remove Class variable

full_model <- lm(Amount ~ ., data=df)
# summary(full_model)

# Save and Print Coefficients
full_model_coeff <- full_model$coefficients
full_model_coeff

```

# Split into Train/Test Sets and Run Model 1,000 times

```{r set_seed, echo=TRUE, warning=FALSE}

set.seed(777)

# Create ID to help with splitting into Train/Test
df$id <- 1:nrow(df)

my_df <- data.frame()

# Run 1,000 Linear models
for(n in 1:1000){
  
  # Split 63.20% of the data into the train set and the rest into test
  train <- df %>% dplyr::sample_frac(0.632)
  test  <- dplyr::anti_join(df, train, by = 'id') 
  
  # Drop id column before running model since it does not have value
  train$id <- NULL
  test$id  <- NULL

  # Run the linear model on all the independent variables
  model <- lm(Amount ~., data=train)
  
  # Capture the predictions on the Test / Holdout set
  predictions <- predict(model, test)
  
  # Save the coefficients, and R-squared for the training and holdout
  save_coeff <- model$coefficients
  save_r2_training <- summary(model)$r.squared
  save_r2_holdout <- cor(test$Amount, predict(model, newdata = test))^2
  
  con <- c(save_coeff, save_r2_training, save_r2_holdout)
  my_df <- rbind(my_df, con)
}

# Remove ID variable and Amount variable
df$id <- NULL
df$Amount <- NULL

# Drop dependent variable Amount and remove na

# my_df <- my_df %>% select(-Amount) %>% na.omit()

# Update Column Names
colnames(my_df)[1] <- "(Intercept)"
colnames(my_df)[2:61] <- names(df)
colnames(my_df)[62] <- "training_r2"
colnames(my_df)[63] <- "holdout_r2"

head(my_df, 3)

```

## Coefficient & R-Squared Distributions

```{r coeff distributions - Age}

hist(my_df$Age, 
     breaks=30,
     xlab = "Coefficients", main = "Coefficient Distribution - Age")

```

### Plot Interpretation: the age coefficients are sometimes negatives which is the opposite of what I would normall think. Generally older people have higher credit, so seeing that the model sometimes says a higher age means less credit is surprising. Overall the plot indicates age tends to have a positive impact on credit amount.

```{r coeff distributions - Residence Duration, echo=TRUE}
hist(my_df$ResidenceDuration, 
     breaks=30,
     xlab = "Coefficients", main = "Coefficient Distribution - Residence Duration", col="lightblue")
```

### Plot Interpretation: 

```{r coeff distributions - Housing Rent, echo=TRUE}
hist(my_df$Housing.Rent, 
     breaks=30,
     xlab = "Coefficients", main = "Coefficient Distribution - Housing Rent", col="lightgreen")
```

```{r distributions - Training R2, echo=TRUE, warning=FALSE}
hist(my_df$training_r2, 
     breaks=30,
     xlab = "Training R-Squared Values", main = "Distribution of Training R-Squared", col="pink")
```

```{r distributions - R2 difference, echo=TRUE, warning=FALSE}
my_df <- my_df %>% mutate(r2_decrease = (training_r2 - holdout_r2)/training_r2)
head(my_df$r2_decrease, 5)

hist(my_df$r2_decrease, 
     breaks=12,
     xlab = "Decrease Values", main = "Distribution of R-Squared Decrease (Training vs. Holdout)",    
     col="lightyellow")

```

### Summary - Interpretation of Above Plots: 

```{r means and sds, echo=TRUE, warning=FALSE}

coefficient_means <- colMeans(my_df)
head(coefficient_means, 5)

coefficient_sds <- sapply(my_df, sd)
head(coefficient_sds, 5)


# Difference between coefficient_means and actual model coefficients
bind <- data.frame(cbind(coefficient_means, save_coeff))
bind$abs_diff <- abs(coefficient_means - save_coeff)
bind$percent_diff <- 100*abs(((coefficient_means - save_coeff) / save_coeff))

print(bind %>% na.omit())
```

## Calculate Confidence Intervals & Width
```{r CI, echo=TRUE, warning=FALSE}

# Confidence Interval for Rep 1,000 Coefficients -------------------------------
# Transposed dataframe of confidence intervals for each variable
rep_conf <- data.frame(t(sapply(my_df[,1:63], function(x) Rmisc::CI(x, ci=0.975)))) #%>% na.omit()

# Calculate Width
# rep_conf$width <- (rep_conf$upper-rep_conf$lower)*sqrt(0.632)
rep_conf$width <- (rep_conf$upper-rep_conf$lower)*sqrt(0.632)

# MANUAL CHECK =============================
# Calculate Means
#means <- data.frame(means=sapply(my_df[1:61], function(x) mean(x)))
#n <- 1000
# Calculate Standard Deviation
#std_dev <- data.frame(std_dev=sapply(my_df[1:61], function(x) sd(x)))

#std_error <- std_dev / sqrt(n)
#alpha = 0.025
#degrees_of_freedom = n-1
#t_score = qt(p=alpha/2, df=degrees_of_freedom,lower.tail=F)
#margin_error <- t_score * std_error

#lower_bound_new <- means - margin_error
#upper_bound_new <- means + margin_error

#x <- cbind(lower_bound_new, upper_bound_new) %>% dplyr::rename(lower_new = 1, upper_new = 2)

#margin <- qnorm(0.975)*std
#rep_CI_low_manual <- means - margin
#rep_CI_high_manual <- means + margin
#manual <- cbind(rep_CI_low_manual, rep_CI_high_manual) %>% 
#                dplyr::rename(lower_manual = 1, upper_manual = 2)


# =============================

# Reorder columns
rep_conf <- rep_conf %>% select(lower, upper, width)

# Keep only valid columns, remove R2 values
rep_conf <- rep_conf[1:61,]

# COMBINE for check
#z <- cbind(rep_conf, manual)
#z$width_manual <- z$upper_manual - z$lower_manual*sqrt(0.632)
#View(z)

# Check row count after ommitting NA
nrow(rep_conf)

# Confidence Interval for Full Model -------------------------------------------
# Calculate confidence interval and rename the columns
full_model_conf <- data.frame(confint(full_model, level=0.975)) %>% 
                   #na.omit() %>% 
                   dplyr::rename(lower_full = 1, upper_full = 2)

# A
full_model_conf <- full_model_conf %>% 
                   #mutate(index=1:nrow(full_model_conf)) %>% 
                   #filter(index %in% (2:48)) %>% 
                   mutate(width_full=upper_full-lower_full)

# Check row count
nrow(full_model_conf)

#t <- cbind(rep_conf, full_model_conf)

row.names(rep_conf) == row.names(full_model_conf)

#View(cbind(row.names(rep_conf), row.names(full_model_conf)))

```
## Determine how many of the repeated sample CI's are tighter
```{r Final Calcs, echo=TRUE, warning=FALSE}

# Combine the 2 dataframes and remove NA values
calc <- cbind(rep_conf, full_model_conf) %>% na.omit()

#Calculate how many of the repeated sample CI’s are tighter or broader than the full model CI’s. If the #width is smaller, the CI is tighter. If the width is bigger, the CI is broader.

# 1 means the CI is tighter (width of repeated is smaller)
calc$tighter_CI_flag <- ifelse(calc$width < calc$width_full, 1, 0)

percent <- sum(calc$tighter_CI_flag)/nrow(calc)
print(percent*100)

```

## Conclusion: 97.87% of the simulated/repeated model's CI's are tighter/smaller. In other words, of the 47 columns left after removing NA's and the class column, 46 of the columns' confidence intervals from the repeated samples are smaller/tighter than those comapred to the CI's from the full model.

